{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d171ead6-ad4a-4549-8327-3450b5deda64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import napari_stress\n",
    "import napari_process_points_and_surfaces as nppas\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm\n",
    "import napari_stl_exporter as npstl\n",
    "import vedo\n",
    "import copy\n",
    "from skimage import data, color, filters, transform\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import os\n",
    "import skimage.io\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from napari.utils import nbscreenshot\n",
    "\n",
    "from napari_stress import reconstruction\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c2a276-3a16-49e0-bb80-158fabdccb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create viewer\n",
    "viewer = napari.Viewer(ndisplay=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e59dc03e-381a-4f6b-8a01-848753e3b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_droplet = 9\n",
    "\n",
    "\n",
    "DATA_ROOT = os.path.join(\"C:\\\\\",\"Users\",\"Heloise\",\"Documents\",\"Data\",\"Naked1\",\"%s\" %num_droplet)\n",
    "\n",
    "image_ini = skimage.io.imread(os.path.join(DATA_ROOT, 'droplet%s.tif' %num_droplet)) #Raw image\n",
    "Dec = skimage.io.imread(os.path.join(DATA_ROOT, 'Dec10_median.tif' ))   #Deconvoluted + median filtered image\n",
    "Edge = skimage.io.imread(os.path.join(DATA_ROOT, 'edges.tif' ))  #After 3D sobel edges filter is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15dd92ad-a5d6-48ed-9c41-1ac81a024b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19979493 0.12449412 0.12449412] 0.12449411815089384\n",
      "[1.60485439 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "\n",
    "#Voxel size in Âµm (with Pixel_size)\n",
    "%run Pixel_Size.ipynb\n",
    "\n",
    "voxelsize = read_tiff_voxel_size(os.path.join(DATA_ROOT, 'Dec10_median.tif'))\n",
    "voxelsize = np.asarray(voxelsize)\n",
    "target_voxelsize = voxelsize[1]\n",
    "\n",
    "print(voxelsize, target_voxelsize)\n",
    "\n",
    "'''\n",
    "vsz = 0.1579\n",
    "vsy = 0.1245\n",
    "vsx = 0.1245\n",
    "target_voxelsize = 0.1245  #microns #microns\n",
    "\n",
    "voxelsize = np.asarray([vsz, vsx, vsy])\n",
    "\n",
    "'''\n",
    "scaling_factors = voxelsize / target_voxelsize\n",
    "\n",
    "print(scaling_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b20c5-7f80-48d2-8c19-0b6f0e1b6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = Dec.shape[0]\n",
    "\n",
    "viewer.add_image(image_ini, name='Raw', scale = voxelsize)\n",
    "viewer.add_image(Dec, name='deconvoluted_data', scale = voxelsize)\n",
    "viewer.add_image(Edge, name='edge', scale = voxelsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57d84d87-48a3-4e79-89f5-38d491e91070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for refinement\n",
    "\n",
    "iterations_PSF = 10\n",
    "smoothing_sigma = 1\n",
    "n_smoothing_iterations = 10\n",
    "resampling_length = 2.5\n",
    "n_tracing_iterations = 10\n",
    "trace_length = 12\n",
    "outlier_tolerance = 0.5\n",
    "Blurred = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86a2ae3a-4158-402b-b8e7-472122b3c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescale\n",
    "\n",
    "scale = np.asarray([target_voxelsize] * 3)  \n",
    "rescaled_image = transform.rescale(Edge[0], scaling_factors,anti_aliasing=False)\n",
    "\n",
    "resampled_image_layer = viewer.add_image(rescaled_image, scale = scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30b0d2-67b7-46ee-a7ad-4a3b4f63aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is sometimes necessary to blurr the image if it's still too noisy\n",
    "blurred_image = filters.gaussian(rescaled_image, sigma=smoothing_sigma)\n",
    "viewer.add_image(blurred_image, scale = scale) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb0ada82-874f-49d8-b291-251129ead496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Surface layer 'surface' at 0x2234d8b7670>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binarization and marching cube\n",
    "\n",
    "threshold = filters.threshold_otsu(blurred_image)\n",
    "binarized_image = blurred_image > threshold*0.9\n",
    "label_image = nsbatwm.connected_component_labeling(binarized_image)\n",
    "binarized_image_layer = viewer.add_labels(label_image, scale = scale)\n",
    "surface = nppas.largest_label_to_surface(label_image)\n",
    "\n",
    "viewer.add_surface(surface, scale = scale)\n",
    "\n",
    "# Smooth surface to simplify the guess of the first points\n",
    "mesh_vedo = vedo.mesh.Mesh((surface[0], surface[1])).clean()\n",
    "n_smoothing_iterations = 10\n",
    "surface_smoothed = nppas.smooth_surface((mesh_vedo.points(), mesh_vedo.faces()),number_of_iterations=n_smoothing_iterations)\n",
    "smoothed_image_layer = viewer.add_surface(surface_smoothed, scale = scale)\n",
    "\n",
    "\n",
    "points_first_guess = nppas.sample_points_from_surface(surface_smoothed, distance_fraction=0.02)  #adapt the distance fraction to have 2000-3000 points\n",
    "viewer.add_points(points_first_guess, size = 1, name = \"points first guess\", scale = scale)\n",
    "\n",
    "points = copy.deepcopy(points_first_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4546bbfe-18b4-4ea2-8009-d712df4cd566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Points layer 'resampled_points' at 0x223579456a0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from napari_stress._reconstruction.toolbox import _resample_pointcloud\n",
    " \n",
    "resampled_points = _resample_pointcloud(points, sampling_length=resampling_length)\n",
    "\n",
    "print(len(resampled_points))\n",
    "viewer.add_points(resampled_points, size = 1, face_color = 'cyan', name = \"resampled_points\", scale = scale)\n",
    "#print(resampled_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df304327-f4a1-42af-9afe-2079ccc07479",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_distance = 0.02  # microns\n",
    "fit_type = 'fancy'   \n",
    "edge_type = 'surface'\n",
    "\n",
    "#surface_density = 0.35  # points/micron^2\n",
    "#curvature_radius = 10  # microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92bb0757-3b5c-45ad-bbef-092e72aca1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979\n",
      "1863\n",
      "1825\n",
      "1795\n",
      "1787\n",
      "1775\n",
      "1764\n",
      "1761\n",
      "1763\n",
      "1759\n"
     ]
    }
   ],
   "source": [
    "from napari_stress._reconstruction.toolbox import _resample_pointcloud\n",
    "\n",
    "for i in range(n_tracing_iterations):\n",
    "    resampled_points = _resample_pointcloud(points, sampling_length=resampling_length)\n",
    "    #viewer.add_points(resampled_points, size = 2, name = \"res\")\n",
    "    traced_points, traced_vectors = reconstruction.trace_refinement_of_surface(\n",
    "        blurred_image,\n",
    "        resampled_points,\n",
    "        selected_fit_type=fit_type,\n",
    "        selected_edge=edge_type,\n",
    "        trace_length=trace_length,\n",
    "        sampling_distance=sampling_distance,\n",
    "        remove_outliers=True,\n",
    "        outlier_tolerance=outlier_tolerance,\n",
    "        interpolation_method=\"linear\")\n",
    "        points = traced_points[0]\n",
    "        #print(len(points))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acda54cb-60d5-4587-8c23-b2a6d25254b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refined_points\n"
     ]
    }
   ],
   "source": [
    "viewer.add_points(traced_points[0], size = 1.5, edge_color = \"blue\", name = \"refined_points\", scale = scale)\n",
    "viewer.add_vectors(traced_vectors[0], **traced_vectors[1], edge_color='red', scale=scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccfe71af-288c-4ca4-ab14-dbe3d09bfcc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (3818335879.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\napari\\lib\\site-packages\\IPython\\core\\compilerop.py:86\u001b[0m, in \u001b[0;36mCachingCompiler.ast_parse\u001b[1;34m(self, source, filename, symbol)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mast_parse\u001b[39m(\u001b[38;5;28mself\u001b[39m, source, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<unknown>\u001b[39m\u001b[38;5;124m'\u001b[39m, symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124;03m\"\"\"Parse code to an AST with the current compiler flags active.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    Arguments are exactly the same as ast.parse (in the standard library),\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    and are passed to the built-in compile function.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPyCF_ONLY_AST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSyntaxError\u001b[0m: EOL while scanning string literal (3818335879.py, line 3)"
     ]
    }
   ],
   "source": [
    "#Save the data in an excel file\n",
    "\n",
    "\n",
    "file_name = '%s_reconstruction.xlsx' %(num_droplet)\n",
    "saving_path = DATA_ROOT.replace(\"\\\\\", \"/\")\n",
    "excel_file = '%s/%s' %(saving_path, file_name)\n",
    "\n",
    "name_info_sup = ['iterations_PSF','smoothing_sigma', 'nb_smoothing', 'nb_points_first_guess', 'resampling_length', 'vector_length', 'Blurred', 'n_iterations', 'outlier_tolerance', 'interpolation_method', 'target_voxel_size']\n",
    "info_sup = [iterations_PSF, smoothing_sigma, n_smoothing_iterations, len(points_first_guess), resampling_length, trace_length, Blurred, n_tracing_iterations, outlier_tolerance, 'linear',target_voxelsize ]\n",
    "\n",
    "data = {nom: [valeur] for nom, valeur in zip(name_info_sup, info_sup)}\n",
    "\n",
    "df1 = pd.DataFrame(traced_points[0])\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "writer = pd.ExcelWriter(excel_file)\n",
    "\n",
    "# Ãcrire chaque DataFrame dans une feuille diffÃ©rente\n",
    "df1.to_excel(writer, sheet_name='data', index=False)\n",
    "df2.to_excel(writer, sheet_name='info', index=False)\n",
    "\n",
    "# Fermer le writer\n",
    "writer.save()\n",
    "\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
